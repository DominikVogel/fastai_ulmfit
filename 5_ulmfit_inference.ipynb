{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'de'\n",
    "wiki = f'{lang}wiki'\n",
    "base_path = Path('data')\n",
    "path = base_path/wiki\n",
    "data_path = path/'germeval'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load classification learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fwd = 'data/dewiki/model/class/fwd/export.pkl'\n",
    "learn_fwd = load_learner(path_fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bwd = 'data/dewiki/model/class/bwd/export.pkl'\n",
    "learn_bwd = load_learner(path_bwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions for simple texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text: Komisch das die Realitätsverweigerung immer von linken erbärmlichen Correctiv Accounts ausgeht...  \n",
    "label: OFFENSE  \n",
    "label_fine: INSULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('INSULT', tensor(1), tensor([0.3995, 0.5468, 0.0500, 0.0037]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Komisch das die Realitätsverweigerung immer von linken erbärmlichen Correctiv Accounts ausgeht...'\n",
    "pred = learn_fwd.predict(text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on GermEval2019 Task 2 (Fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GermEval2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['text','label','label_fine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_path/'germeval2019/germeval2019GoldLabelsSubtask1_2.txt',\n",
    "                sep ='\\t', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('@\\w+', ' ', text)\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "df_test['text'] = df_test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7301)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_fwd = learn_fwd.dls.test_dl(df_test, with_labels=True)\n",
    "preds_fwd = learn_fwd.get_preds(dl=dl_fwd)\n",
    "accuracy(*preds_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7374)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_bwd = learn_bwd.dls.test_dl(df_test, with_labels=True)\n",
    "preds_bwd = learn_bwd.get_preds(dl=dl_bwd)\n",
    "accuracy(*preds_bwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Forward + Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7456)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (preds_fwd[0] + preds_bwd[0]) / 2\n",
    "accuracy(preds, preds_fwd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 'macro'\n",
    "precision = Precision(average=avg)\n",
    "recall = Recall(average=avg)\n",
    "f1score = F1Score(average=avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5863656019734342"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(torch.argmax(preds, axis=1), preds_fwd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4930981710582918"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(torch.argmax(preds, axis=1), preds_fwd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5254420614467545"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(torch.argmax(preds, axis=1), preds_fwd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreation with fastinference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the predictions with [fastinference](https://muellerzr.github.io/fastinference/). Installation:  \n",
    "`pip install fastinference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.668\" style=\"background-color: rgba(183, 224, 117, 0.5);\">▁xxbos</span> <span title=\"0.415\" style=\"background-color: rgba(254, 228, 147, 0.5);\">▁xxmaj</span> <span title=\"0.747\" style=\"background-color: rgba(134, 203, 102, 0.5);\">▁komisch</span> <span title=\"0.653\" style=\"background-color: rgba(189, 226, 120, 0.5);\">▁das</span> <span title=\"0.574\" style=\"background-color: rgba(227, 243, 153, 0.5);\">▁die</span> <span title=\"0.415\" style=\"background-color: rgba(254, 228, 147, 0.5);\">▁xxmaj</span> <span title=\"0.765\" style=\"background-color: rgba(124, 198, 101, 0.5);\">▁realität</span> <span title=\"0.568\" style=\"background-color: rgba(228, 244, 155, 0.5);\">s</span> <span title=\"0.742\" style=\"background-color: rgba(137, 204, 102, 0.5);\">verweiger</span> <span title=\"0.886\" style=\"background-color: rgba(36, 157, 82, 0.5);\">ung</span> <span title=\"0.729\" style=\"background-color: rgba(147, 208, 103, 0.5);\">▁immer</span> <span title=\"0.641\" style=\"background-color: rgba(195, 229, 124, 0.5);\">▁von</span> <span title=\"0.773\" style=\"background-color: rgba(119, 196, 100, 0.5);\">▁linken</span> <span title=\"0.620\" style=\"background-color: rgba(207, 234, 132, 0.5);\">▁erbärmlich</span> <span title=\"0.686\" style=\"background-color: rgba(173, 220, 110, 0.5);\">en</span> <span title=\"0.415\" style=\"background-color: rgba(254, 228, 147, 0.5);\">▁xxmaj</span> <span title=\"0.682\" style=\"background-color: rgba(175, 220, 111, 0.5);\">▁correct</span> <span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">iv</span> <span title=\"0.415\" style=\"background-color: rgba(254, 228, 147, 0.5);\">▁xxmaj</span> <span title=\"0.735\" style=\"background-color: rgba(142, 206, 103, 0.5);\">▁accounts</span> <span title=\"0.615\" style=\"background-color: rgba(209, 235, 133, 0.5);\">▁aus</span> <span title=\"0.911\" style=\"background-color: rgba(22, 145, 76, 0.5);\">geht</span> <span title=\"0.605\" style=\"background-color: rgba(215, 238, 137, 0.5);\">▁...</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastinference.inference.text import intrinsic_attention\n",
    "learn_fwd.intrinsic_attention(text, class_id=np.argmax(pred[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
