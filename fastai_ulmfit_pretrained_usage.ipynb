{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of ULMFiT-pretrained models and the fastai_ulmfit library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/floleuerer/fastai_ulmfit/blob/main/fastai_ulmfit_pretrained_usage.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install required packages for **Colab** and import them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -Uq fastai==2.2.7 sentencepiece==0.1.95 fastcore==1.3.19 fastai-ulmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai_ulmfit.pretrained import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare GermEval2019 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a minimal Example and we are using a part of the **GermEval2019 Task 1** Training data - so the results will be worse than with the complete dataset. \n",
    "\n",
    "https://projects.fzai.h-da.de/iggsa/data-2019/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P tmp/ https://projects.fzai.h-da.de/iggsa/wp-content/uploads/2019/09/germeval2019.training_subtask1_2_korrigiert.txt\n",
    "!wget -P tmp/ https://projects.fzai.h-da.de/iggsa/wp-content/uploads/2019/08/germeval2019GoldLabelsSubtask1_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['text','label','label_fine']\n",
    "\n",
    "df_train = pd.read_csv(f'tmp/germeval2019.training_subtask1_2_korrigiert.txt', sep = '\\t', names=names)\n",
    "df_train['is_valid'] = False\n",
    "\n",
    "df_test = pd.read_csv('tmp/germeval2019GoldLabelsSubtask1_2.txt', sep ='\\t', names=names)\n",
    "df_test['is_valid'] = True\n",
    "\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some simple preprocessing - remove @-mentions and links from the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('@\\w+', ' ', text)\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of ULMFiT-pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `fastai_ulmfit` provides the following helper functions to easily use the **pretrained models**\n",
    "- create a tokenizer `tokenizer_from_pretrained`\n",
    "- learner to fine-tune the language model `language_model_from_pretrained`\n",
    "- train a classifier from the fine-tuned language model `text_classifier_from_lm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tokenizer from pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenizer_from_pretrained` creates a SentencePieceTokenizer-Tokenizer with the parameters (e.g. `vocab_sz`) the model and tokenizer was trained with.\n",
    "\n",
    "**Will be used for both the language model fine-tuning and the training of the classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/ulmfit-dewiki'\n",
    "tok = tokenizer_from_pretrained(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `Dataloaders` for the **language model fine-tuning** from dataframe and pass the created **tokenizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblocks = DataBlock(blocks=(TextBlock.from_df('text', tok=tok, is_lm=True)),\n",
    "                    get_x=ColReader('text'), \n",
    "                    splitter=ColSplitter())\n",
    "dls = dblocks.dataloaders(df, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `language_model_from_pretrained` calls `language_model_learner` and creates a LMLearner from the pretrained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_from_pretrained(dls, url=url, drop_mult=1).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr, moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, slice(lr/100,lr), moms=(0.8,0.7,0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the fine-tuned model to `path` (default is `learn.model_dir`) with all required files (Model, Encoder, Vocab and SentencePiece-Model)\n",
    "\n",
    "`path` and `vocab` will be used for training the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = learn.save_lm('tmp/test_lm')\n",
    "vocab = learn.dls.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblocks = DataBlock(blocks=(TextBlock.from_df('text', tok=tok, vocab=vocab), CategoryBlock),\n",
    "                    get_x=ColReader('text'),\n",
    "                    get_y=ColReader('label'), \n",
    "                    splitter=ColSplitter())\n",
    "dls = dblocks.dataloaders(df, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text_classifier_from_lm` calls `text_classifier_learner` to create a learner **from the fine-tuned model** `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_from_lm(dls, path=path, metrics=[accuracy]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(5, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
